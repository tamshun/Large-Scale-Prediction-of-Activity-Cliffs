{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shap\n",
    "from Tools.ReadWrite import LoadJson\n",
    "from Kernels.Kernel                    import funcTanimotoKernel_MMPKernel\n",
    "from Fingerprint.Hash2BitManager       import Hash2Bits, FindBitLength\n",
    "from sklearn.svm import SVC\n",
    "from collections                         import defaultdict\n",
    "from functools import partial\n",
    "#from sklearnex                           import patch_sklearn\n",
    "\n",
    "#patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHAP():\n",
    "    \n",
    "    def __init__(self, target:str, model:str, trial:int) -> None:\n",
    "        self.target = target\n",
    "        self.model  = model\n",
    "        self.trial  = trial\n",
    "        \n",
    "        self.data_dir  = './Dataset/Data/'\n",
    "        self.fp_dir    = './Dataset/ECFP/'\n",
    "        self.log_dir   = './Log_wodirection_trtssplit/'\n",
    "        self.param_dir = self.log_dir + model + '/Models/' \n",
    "        \n",
    "        self.col = ['core', 'sub1', 'sub2', 'overlap']       \n",
    "     \n",
    "        \n",
    "    def _load(self):\n",
    "        \n",
    "        log   = pd.read_csv('./Log_wodirection_trtssplit/%s/%s_trial%d.tsv' %(self.model, self.target, self.trial), sep='\\t', index_col='ids')\n",
    "        \n",
    "        data  = pd.read_csv(self.data_dir+'%s.tsv'%self.target, sep='\\t', index_col='id')\n",
    "        ecfp  = pd.read_csv(self.fp_dir+'%s.tsv'%self.target, sep='\\t', index_col='id')\n",
    "        \n",
    "        return log, data, ecfp\n",
    "    \n",
    "    \n",
    "    def _load_param(self):\n",
    "        return LoadJson(self.param_dir + '%s_trial%d.json'%(self.target, self.trial))\n",
    "    \n",
    "    \n",
    "    def _load_nn(self):\n",
    "        return torch.load(self.param_dir + '%s_trial%d.pth'%(self.target, self.trial))\n",
    "    \n",
    "    \n",
    "    def _bitlength(self):\n",
    "        \n",
    "        nbits_c = FindBitLength(self.ecfp, [self.col[0]])\n",
    "        nbits_s = FindBitLength(self.ecfp, self.col[1:] )\n",
    "        \n",
    "        return nbits_c, nbits_s\n",
    "    \n",
    "    \n",
    "    def _trtssplit(self):\n",
    "        \n",
    "        tsidx = self.log.index\n",
    "        tridx = np.setdiff1d(self.data.index, tsidx)\n",
    "        \n",
    "        return tridx, tsidx\n",
    "    \n",
    "    \n",
    "    def analyze(self):\n",
    "        \n",
    "        tridx, tsidx  = self._trtssplit()\n",
    "        self.trX, self.trY, self.tsX = self._make_input(tridx, tsidx)\n",
    "        ml            = self._reload_ml(self.trX, self.trY)\n",
    "        ml_score      = self._select_scorefunc(ml)\n",
    "        explainer     = self._init_shap(ml_score, self.trX)\n",
    "        return explainer\n",
    "    \n",
    "    \n",
    "    def analyze_nn(self):\n",
    "        \n",
    "        tridx, tsidx  = self._trtssplit()\n",
    "        self.tr, self.ts = self._make_input(tridx, tsidx)\n",
    "        ml            = self._reload_ml(self.tr, self.tr)\n",
    "        ml_score      = self._select_scorefunc(ml)\n",
    "        explainer     = self._init_shap(ml_score, self.tr)\n",
    "        return explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHAP_SVM(SHAP):\n",
    "    \n",
    "    def __init__(self, target: str, trial: int) -> None:\n",
    "        \n",
    "        super().__init__(target=target, model='SVM', trial=trial)\n",
    "        \n",
    "        self.log, self.data, self.ecfp = self._load()\n",
    "        self.param                     = self._load_param()\n",
    "        self.len_c, self.len_s         = self._bitlength()\n",
    "    \n",
    "    \n",
    "    def _make_input(self, tridx, tsidx):\n",
    "        \n",
    "        df_trX = self.ecfp.loc[tridx, :]\n",
    "        df_trY = self.data.loc[tridx, 'class']\n",
    "        df_tsX = self.ecfp.loc[tsidx, :]\n",
    "\n",
    "        forward  = Hash2Bits(subdiff=False, sub_reverse=False)\n",
    "        trX, trY = forward.GetMMPfingerprints_DF_unfold(df=df_trX, Y=df_trY, cols=self.col, nbits=[self.len_c, self.len_s], overlap=\"concat\")\n",
    "        tsX      = forward.GetMMPfingerprints_DF_unfold(df=df_tsX, cols=self.col, nbits=[self.len_c, self.len_s], overlap=\"concat\")\n",
    "\n",
    "        return trX, trY, tsX\n",
    "    \n",
    "    \n",
    "    def _reload_ml(self, trX, trY):\n",
    "        \n",
    "        kernelf = partial(funcTanimotoKernel_MMPKernel, len_c=self.len_c)\n",
    "        ml = SVC(kernel=kernelf, **self.param)\n",
    "        ml.fit(trX, trY)\n",
    "        \n",
    "        return ml\n",
    "    \n",
    "    def _select_scorefunc(self, ml):\n",
    "        return ml.decision_function\n",
    "        \n",
    "    def _init_shap(self, ml_score, trdata, proportion=\"average\"):\n",
    "        \n",
    "        model = self.model.lower()\n",
    "        \n",
    "        # Kernel explaner will be used for non-tree-based model \n",
    "        explainer = shap.KernelExplainer(model = ml_score,\n",
    "                                         data  = trdata,\n",
    "                                         link  = \"identity\"\n",
    "                                        )\n",
    "                        \n",
    "        return explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHAP_TreeBase(SHAP):\n",
    "    \n",
    "    def __init__(self, target: str, trial: int) -> None:\n",
    "        \n",
    "        super().__init__(target=target, model='XGBoost', trial=trial)\n",
    "        \n",
    "        self.log, self.data, self.ecfp = self._load()\n",
    "        self.param                     = self._load_param()\n",
    "        self.len_c, self.len_s         = self._bitlength()\n",
    "    \n",
    "    \n",
    "    def _make_input(self, tridx, tsidx):\n",
    "        \n",
    "        df_trX = self.ecfp.loc[tridx, :]\n",
    "        df_trY = self.data.loc[tridx, 'class']\n",
    "        df_tsX = self.ecfp.loc[tsidx, :]\n",
    "\n",
    "        forward  = Hash2Bits(subdiff=False, sub_reverse=False)\n",
    "        trX, trY = forward.GetMMPfingerprints_DF_unfold(df=df_trX, Y=df_trY, cols=self.col, nbits=[self.len_c, self.len_s], overlap=\"concat\")\n",
    "        tsX      = forward.GetMMPfingerprints_DF_unfold(df=df_tsX, cols=self.col, nbits=[self.len_c, self.len_s], overlap=\"concat\")\n",
    "\n",
    "        return trX, trY, tsX\n",
    "    \n",
    "    \n",
    "    def _reload_ml(self, trX, trY):\n",
    "        \n",
    "        if self.model == 'XGBoost':\n",
    "            import xgboost as xgb\n",
    "            ml = xgb.XGBClassifier(**self.param)\n",
    "            ml.fit(trX, trY)\n",
    "\n",
    "        elif self.model == 'Random_Forest':\n",
    "            from sklearn.ensemble import RandomForestClassifier as rf\n",
    "            ml = rf(**self.param)\n",
    "            ml.fit(trX, trY)\n",
    "        \n",
    "        return ml\n",
    "    \n",
    "    \n",
    "    def _select_scorefunc(self, ml):\n",
    "        return ml.predict_proba\n",
    "    \n",
    "        \n",
    "    def _init_shap(self, ml_score, trdata):\n",
    "        \n",
    "        # Kernel explaner will be used for non-tree-based model \n",
    "        explainer = shap.TreeExplainer(model         = ml_score,\n",
    "                                       data          = trdata,\n",
    "                                       model_output  = \"probability\"\n",
    "                                      )\n",
    "                        \n",
    "        return explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data                  import DataLoader, Subset\n",
    "from joblib.externals.loky.backend.context import get_context\n",
    "from functools import partial\n",
    "\n",
    "def torch2numpy(x):\n",
    "    return x.to(\"cpu\").detach().numpy().copy()\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, fpset, label):\n",
    "        self.X = fpset\n",
    "        self.y = label.reshape([label.shape[0],1])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor_X = torch.FloatTensor(self.X[idx,:])\n",
    "        tensor_y = torch.FloatTensor(self.y[idx])\n",
    "        return tensor_X, tensor_y \n",
    "    \n",
    "class FullyConnectedNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, arg, random_seed=0):\n",
    "        \n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        torch.manual_seed(random_seed)\n",
    "        torch.cuda.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "        hidden_list  = arg['node_list']\n",
    "        W_list       = [nn.Linear(hidden_list[0], hidden_list[1], bias=True)]\n",
    "        self.dropout = nn.Dropout(p=arg['drop_rate'])\n",
    "        self.active_function = nn.ReLU()\n",
    "        \n",
    "        for num in range(len(hidden_list)-2):\n",
    "            W_list.extend([self.active_function, self.dropout, nn.Linear(hidden_list[num+1], hidden_list[num+2], bias=True)])\n",
    "                \n",
    "        modulelist  =  nn.ModuleList(W_list) \n",
    "        self.W      =  nn.Sequential(*modulelist)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.W(x)  \n",
    "\n",
    "            \n",
    "def predict_proba(X):\n",
    "    output_act = nn.Sigmoid()\n",
    "    out = output_act(X)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def test(model, dataloader, device='cpu'):\n",
    "    model.to(device)\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    threshold = torch.tensor([0.5], device=device)\n",
    "    pred_score_all, pred_all, proba_all, y_all = [], [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            score      = model(X)\n",
    "            proba      = predict_proba(score)\n",
    "            pred       = (proba>threshold).float()*1\n",
    "            \n",
    "            pred_score_all += torch2numpy(score).reshape(-1).tolist()\n",
    "            pred_all       += torch2numpy(pred).reshape(-1).tolist()\n",
    "            proba_all      += torch2numpy(proba).reshape(-1).tolist()\n",
    "            y_all          += torch2numpy(y).reshape(-1).tolist() \n",
    "            \n",
    "    return pred_score_all, pred_all, proba_all\n",
    "\n",
    "\n",
    "def predict_proba(X):\n",
    "    output_act = nn.Sigmoid()\n",
    "    out = output_act(X)\n",
    "    \n",
    "    return out\n",
    "\n",
    "           \n",
    "class SHAP_NN(SHAP):\n",
    "    \n",
    "    def __init__(self, target: str, trial: int) -> None:\n",
    "        \n",
    "        super().__init__(target=target, model='FCNN', trial=trial)\n",
    "        \n",
    "        self.log, self.data, self.ecfp = self._load()\n",
    "        self.param                     = self._load_param()\n",
    "        self.nn                        = self._load_nn()\n",
    "        self.len_c, self.len_s         = self._bitlength()\n",
    "    \n",
    "    \n",
    "    def _make_input(self, tridx, tsidx):\n",
    "        \n",
    "        df_trX = self.ecfp.loc[tridx, :]\n",
    "        df_trY = self.data.loc[tridx, 'class']\n",
    "        df_tsX = self.ecfp.loc[tsidx, :]\n",
    "        df_tsY = self.data.loc[tsidx, 'class']\n",
    "\n",
    "        forward  = Hash2Bits(subdiff=False, sub_reverse=False)\n",
    "        trX, trY = forward.GetMMPfingerprints_DF_unfold(df=df_trX, Y=df_trY, cols=self.col, nbits=[self.len_c, self.len_s], overlap=\"concat\")\n",
    "        tsX, tsY = forward.GetMMPfingerprints_DF_unfold(df=df_tsX, Y=df_tsY, cols=self.col, nbits=[self.len_c, self.len_s], overlap=\"concat\")\n",
    "\n",
    "        dataloader_tr = DataLoader(Dataset(fpset=trX, label=trY),\n",
    "                                   shuffle=True,\n",
    "                                   batch_size=self.param['batch_size'],\n",
    "                                   )\n",
    "        \n",
    "        dataloader_ts = DataLoader(Dataset(fpset=tsX, label=tsY),\n",
    "                                   batch_size=self.param['batch_size'],\n",
    "                                   shuffle=False,\n",
    "                                   num_workers=2,\n",
    "                                   multiprocessing_context=get_context('loky'),\n",
    "                                   )\n",
    "        \n",
    "        return dataloader_tr, dataloader_ts\n",
    "    \n",
    "    \n",
    "    def _reload_ml(self, trX, trY):\n",
    "        \n",
    "        ml = FullyConnectedNN(**self.param)\n",
    "        ml.load_state_dict(self.nn)\n",
    "        ml.eval()\n",
    "        \n",
    "        return ml\n",
    "    \n",
    "    \n",
    "    def _select_scorefunc(self, ml):\n",
    "        scoref = partial(test, model=ml)\n",
    "        return scoref\n",
    "    \n",
    "        \n",
    "    def _init_shap(self, ml_score, trdata):\n",
    "        \n",
    "        # Kernel explaner will be used for non-tree-based model \n",
    "        explainer = shap.DeepExplainer(model = ml_score,\n",
    "                                       X     = trdata,\n",
    "                                      )\n",
    "                        \n",
    "        return explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'CHEMBL204'\n",
    "trial = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "exp = SHAP_SVM(target, trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    $ Overlap option is selected as concat\n",
      "    $ Overlap option is selected as concat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 1525 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    }
   ],
   "source": [
    "explainer = exp.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:57<00:00, 118.89s/it]\n"
     ]
    }
   ],
   "source": [
    "fcs = explainer.shap_values(exp.tsX[:2,:], nsamples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(fcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f7d60dd648d82e5ef4c4f9ba1946e62b6642da77143b0b983cfb14b8b57c97a"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('rdkit': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
